# Introduction to MPI

## 1. Message passing
```{dropdown}
- Processes communicate via messages
- Messages can be:
  - Raw data used in actual calculations
  - Signals and acknowledgements for the receiving processes regarding the workflow.
```


## 2. History of MPI: early 80s
```{dropdown}
- Various message passing environments were developed.
- Many similar fundamental concepts:
  - Cosmic Cube and nCUBE/2 (Caltech), 
  - P4 (Argonne), 
  - PICL and PVM (Oakridge), 
  - LAM (Ohio SC)
```


## 3. History of MPI: 1991-1992
```{dropdown}
- More than 80 researchers from different institutions in US and Europe agreed 
to develop and implement a common standard for message passing.
- Follow-up first meeting of the working group hosted at Supercomputing 1992 in 
Minnesota. 

<img src="../assets/figure/07-intro-mpi/01.png" alt="MPI letters" style="height:600px">
```


## 4. After finalization of working technical draft
```{dropdown}
- MPI becomes the *de-facto* standard for distributed memory parallel 
programming.
- Available on every popular operating system and architecture.
- Interconnect manufacturers commonly provide MPI implementations optimized 
for their hardware.
- MPI standard defines interfaces for C, C++, and Fortran.
- Language bindings available for many popular languages (quality varies)
  - Python (mpi4py)
  - Java (no longer active)
```


## 5. 1994: MPI-1
```{dropdown}
- Communicators
  - Information about the runtime environments
  - Creation of customized topologies
- Point-to-point communication
  - Send and receive messages
  - Blocking and non-blocking variations
- Collectives
  - Broadcast and reduce
  - Gather and scatter
```


## 6. 1998: MPI-2
```{dropdown}
- One-sided communication (non-blocking)
  - Get & Put (remote memory access)
- Dynamic process management
  - Spawn
- Parallel I/O
  - Multiple readers and writers for a single file
  - Requires file-system level support (LustreFS, PVFS)
```


## 7. 2012: MPI-3
```{dropdown}
- Revised remote-memory access semantic
- Fault tolerance model
- Non-blocking collective communication
- Access to internal variables, states, and counters for performance 
evaluation purposes
```


## 8. Hands-on: taz and submitty
```{dropdown}
- Your account (login/password) will work on both `taz` and `submitty`. 
- `USERNAME` represents the login name that you received in email.
- To access `taz` from a terminal:

~~~
$ ssh USERNAME@taz.cs.wcupa.edu
~~~
{: .language-bash}

- To access `submitty` from a terminal: 

~~~
$ ssh USERNAME@submitty.cs.wcupa.edu
~~~
{: .language-bash}

- The environments on `taz` and `submitty` are similar to one another. 
In the remainder of these lectures, example screenshots will be taken 
from `submitty`, but all commands will work on `taz` as well. 
```


## 9. Hands-on: create and compile MPI codes
```{dropdown}
- Create a directory named `intro-mpi`
- Change into `intro-mpi`

~~~
$ cd
$ mkdir intro-mpi
$ cd intro-mpi
~~~
{: .language-bash}

- To create a file from terminal, run `nano -c file_name`. 
- When finish editing, press `Ctrl-X` to select `Quit and Save`. 
- Press `Y` to confirm that you want to save. 
- Press `Enter` to confirm that you are saving to `file_name`. 
- Inside `intro-mpi`, create a file named `first.c` with the following
contents

<script src="https://gist.github.com/linhbngo/05955842d2a7ce40c9723292a2ded118.js?file=first.c"></script>

- Compile and run `first.c`:

~~~
$ mpicc -o first first.c
$ mpirun -np 1 ./first
$ mpirun -np 2 ./first
$ mpirun -np 4 ./first
~~~
{: .language-bash}

- Both `taz` and `submitty` only have four computing cores, therefore we can (should) 
only run to a maximum of four processes. 

<img src="../assets/figure/07-intro-mpi/02.png" alt="compile and run first.c" style="height:350px">
```


## 10. MPI in a nutshell
```{dropdown}
- All processes are launched at the beginning of the program execution.
  - The number of processes are user-specified
  - This number could be modified during runtime (MPI-2 standards)
  - Typically, this number is matched to the total number of cores 
  available across the entire cluster
- All processes have their own memory space and have access to the same source codes.
- `MPI_Init`: indicates that all processes are now working in message-passing mode.
- `MPI_Finalize`: indicates that all processes are now working in sequential mode 
(only one process active) and there are no more message-passing activities. 
```


## 11. MPI in a nutshell
```{dropdown}
- `MPI_COMM_WORLD`: Global communicator
- `MPI_Comm_rank`: return the rank of the calling process
- `MPI_Comm_size`: return the total number of processes that are part of 
the specified communicator. 
- `MPI_Get_processor_name`: return the name of the processor (core) running the process. 
```


## 12. MPI communicators (first defined in MPI-1)
```{dropdown}
MPI defines communicator groups for point-to-point and collective 
communications:
- Unique IDs (rank) are defined for individual processes within a communicator 
group.
- Communications are performed based on these IDs.
- Default global communication (`MPI_COMM_WORLD`) contains all processes.
- For `N` processes, ranks go from `0` to `Nâˆ’1`. 
```


## 13. Hands-on: hello.c
```{dropdown}
- Inside `intro-mpi`, create a file named `hello.c` with the following
contents

<script src="https://gist.github.com/linhbngo/05955842d2a7ce40c9723292a2ded118.js?file=hello.c"></script>

- Compile and run `hello.c`:

~~~
$ mpicc -o hello hello.c
$ mpirun -np 1 ./hello
$ mpirun -np 2 ./hello
$ mpirun -np 4 ./hello
~~~
{: .language-bash}

<img src="../assets/figure/07-intro-mpi/03.png" alt="compile and run hello.c" style="height:350px">
```


## 14. Hands-on: evenodd.c
```{dropdown}
- In MPI, processes' ranks are used to enforce execution/exclusion of code 
segments within the original source code. 
- Inside `intro-mpi`, create a file named `evenodd.c` with the following
contents

<script src="https://gist.github.com/linhbngo/05955842d2a7ce40c9723292a2ded118.js?file=evenodd.c"></script>

- Compile and run `evenodd.c`:

~~~
$ mpicc -o evenodd evenodd.c
$ mpirun -np 1 ./evenodd
$ mpirun -np 2 ./evenodd
$ mpirun -np 4 ./evenodd
~~~
{: .language-bash}

<img src="../assets/figure/07-intro-mpi/04.png" alt="compile and run evenodd.c" style="height:350px">
```


## 15. Hands-on: rank_size.c
```{dropdown}
- In MPI, the values of ranks and size can be used as means to calculate 
and distribute workload (data) among the processes. 
- Inside `intro-mpi`, create a file named `rank_size.c` with the following
contents

<script src="https://gist.github.com/linhbngo/05955842d2a7ce40c9723292a2ded118.js?file=rank_size.c"></script>

- Compile and run `rank_size.c`:

~~~
$ mpicc -o rank_size rank_size.c
$ mpirun -np 1 ./rank_size
$ mpirun -np 2 ./rank_size
$ mpirun -np 4 ./rank_size
~~~
{: .language-bash}

<img src="../assets/figure/07-intro-mpi/05.png" alt="compile and run rank_size.c" style="height:800px">

```





